# LLM Judger com Ollama

Sistema para avalia√ß√£o de tradu√ß√µes e equival√™ncia sem√¢ntica usando modelos de linguagem locais via Ollama.

## üöÄ Caracter√≠sticas

- **Integra√ß√£o com Ollama**: Usa modelos LLM locais para avalia√ß√£o
- **M√∫ltiplos tipos de avalia√ß√£o**: Tradu√ß√£o, equival√™ncia sem√¢ntica, qualidade
- **Processamento em lote**: Avalia m√∫ltiplos pares de senten√ßas simultaneamente
- **Processamento de datasets CSV**: Carrega e processa arquivos CSV automaticamente
- **Concorr√™ncia controlada**: Gerencia m√∫ltiplas inst√¢ncias de modelos
- **Logging detalhado**: Debug e monitoramento de opera√ß√µes
- **Tratamento robusto de erros**: Retry autom√°tico e fallbacks
- **Exporta√ß√£o de resultados**: Salva resultados diretamente no CSV com colunas adicionais

## üìã Pr√©-requisitos

1. **Ollama instalado e rodando**:
   ```bash
   # Instalar Ollama (se n√£o estiver instalado)
   curl -fsSL https://ollama.ai/install.sh | sh
   
   # Iniciar o servidor Ollama
   ollama serve
   ```

2. **Modelos baixados**:
   ```bash
   # Exemplos de modelos recomendados
   ollama pull llama2
   ollama pull mistral
   ollama pull codellama
   ```

3. **Depend√™ncias Python**:
   ```bash
   pip install aiohttp python-dotenv pandas
   ```

## üõ†Ô∏è Instala√ß√£o

1. Clone ou baixe o projeto
2. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt
   ```
3. Certifique-se de que o Ollama est√° rodando:
   ```bash
   ollama serve
   ```

## üéØ Como Usar

### Uso Interativo

Execute o script principal:

```bash
python main.py
```

O sistema ir√°:
1. Testar a conex√£o com o Ollama
2. Listar modelos dispon√≠veis
3. Permitir configurar modelos e inst√¢ncias
4. Oferecer op√ß√µes de entrada:
   - Adicionar pares manualmente
   - Processar dataset CSV
   - Processar pares adicionados
5. Processar e mostrar resultados

### Uso Program√°tico

Veja o arquivo `exemplo_uso.py` para exemplos de como usar o sistema programaticamente:

```python
from main import OllamaClient, JudgerSystem, SentencePair, ModelConfig

# Inicializar cliente
client = OllamaClient(base_url="http://localhost:11434")
judger = JudgerSystem(client)

# Criar par de senten√ßas
pair = SentencePair(
    source_text="Hello, how are you?",
    target_text="Ol√°, como voc√™ est√°?",
    source_language="en",
    target_language="pt"
)

# Fazer julgamento
result = await judger.judge_sentence_pair(pair, "llama2", "translation")
```

### Processamento de Datasets CSV

O sistema suporta processamento autom√°tico de datasets CSV:

```python
from main import CSVProcessor, JudgerSystem, ModelConfig

# Carregar dataset CSV
processor = CSVProcessor("meu_dataset.csv")
processor.load_csv()

# Configurar colunas e idiomas
processor.validate_columns("texto_original", "texto_traduzido")
processor.set_languages("en", "pt")

# Converter para pares de senten√ßas
sentence_pairs = processor.get_sentence_pairs()

# Processar com modelo
configs = [ModelConfig(name="llama2", instances=2)]
results = await judger.batch_judgment(sentence_pairs, configs, "translation")

# Salvar resultados no CSV
processor.save_results(results, "resultados.csv")
```

#### Formato do CSV

O CSV deve ter pelo menos duas colunas com os textos a serem avaliados:

```csv
texto_original,texto_traduzido
Hello, how are you?,Ol√°, como voc√™ est√°?
Good morning!,Bom dia!
Thank you very much.,Muito obrigado.
```

#### Colunas de Resultado

Ap√≥s o processamento, o CSV ser√° expandido com as seguintes colunas:

- **resultado**: "Correto" ou "Incorreto"
- **explicacao**: Explica√ß√£o detalhada do julgamento
- **confianca**: Score de confian√ßa (0.0-1.0)
- **modelo**: Nome do modelo usado
- **timestamp**: Data e hora do processamento

## üìä Tipos de Avalia√ß√£o

### 1. Avalia√ß√£o de Tradu√ß√£o
- Verifica precis√£o da tradu√ß√£o
- Considera flu√™ncia e adequa√ß√£o cultural
- Identifica erros gramaticais e de contexto

### 2. Equival√™ncia Sem√¢ntica
- Foca no significado, n√£o na tradu√ß√£o literal
- Considera diferentes formas de expressar a mesma ideia
- Avalia preserva√ß√£o da inten√ß√£o comunicativa

### 3. Avalia√ß√£o de Qualidade
- Analisa qualidade lingu√≠stica de ambas as senten√ßas
- Considera gram√°tica, clareza, naturalidade
- Avalia adequa√ß√£o ao contexto

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

Crie um arquivo `.env` (opcional):

```env
OLLAMA_URL=http://localhost:11434
```

### Par√¢metros do Cliente

```python
client = OllamaClient(
    base_url="http://localhost:11434",  # URL do Ollama
    max_concurrent_requests=4,          # M√°ximo de requisi√ß√µes simult√¢neas
    timeout=60                          # Timeout em segundos
)
```

## üîß Solu√ß√£o de Problemas

### Ollama n√£o conecta
- Verifique se o Ollama est√° rodando: `ollama serve`
- Confirme a URL: padr√£o √© `http://localhost:11434`
- Verifique firewall/proxy

### Nenhum modelo encontrado
- Liste modelos: `ollama list`
- Baixe um modelo: `ollama pull llama2`

### Modelo n√£o responde
- Teste o modelo: `ollama run llama2`
- Verifique se h√° mem√≥ria suficiente
- Tente um modelo menor

### Erro de parsing JSON
- Ative modo debug para ver respostas detalhadas
- O sistema tem fallback para respostas n√£o estruturadas

## üìà Monitoramento

O sistema inclui logging detalhado:

- **INFO**: Opera√ß√µes principais e status
- **WARNING**: Problemas recuper√°veis
- **ERROR**: Falhas cr√≠ticas
- **DEBUG**: Detalhes t√©cnicos (ativar com modo debug)

## ü§ù Contribui√ß√£o

Para contribuir:
1. Fa√ßa fork do projeto
2. Crie uma branch para sua feature
3. Implemente e teste
4. Submeta um pull request

## üìÑ Licen√ßa

Este projeto est√° sob licen√ßa MIT. Veja o arquivo LICENSE para detalhes.

## üìÅ Arquivos do Projeto

- **`main.py`**: Sistema principal com todas as funcionalidades
- **`exemplo_uso.py`**: Exemplos de uso program√°tico
- **`exemplo_csv.py`**: Exemplo de processamento de CSV
- **`teste_rapido.py`**: Script de teste r√°pido
- **`exemplo_dataset.csv`**: Dataset de exemplo para testes
- **`requirements.txt`**: Depend√™ncias do projeto
- **`README.md`**: Esta documenta√ß√£o

## üÜò Suporte

Para problemas ou d√∫vidas:
1. Verifique a se√ß√£o de solu√ß√£o de problemas
2. Ative o modo debug para mais informa√ß√µes
3. Teste com o arquivo `exemplo_dataset.csv` fornecido
4. Execute `python teste_rapido.py` para verificar a instala√ß√£o
5. Abra uma issue no reposit√≥rio